# -*- coding: utf-8 -*-
"""CSE422_15_Lab_GroupNo011_Code_23241101_21201596.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IDfwAv7CzqCpftKzEzRsu0BR_CsErOP
"""

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import  GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""## Data Visualization"""

data = pd.read_csv('/content/drive/MyDrive/modified_csv_file.csv')
data

data.shape

class_distribution = data['phishing'].value_counts()
print("Class Distribution:\n", class_distribution)

sns.countplot(x='phishing', data=data, palette='viridis')
plt.title('Class Distribution of websites')
plt.xlabel('Phishing? (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

plt.pie(data['phishing'].value_counts(),labels=["Phishing","Legit"],autopct='%.1f%%')
plt.title("Phishing Count")
plt.show()

"""## Handling Missing Values"""

data.isnull().sum()

"""### Imputing missing Values"""

from sklearn.impute import SimpleImputer

for column in data.columns:
  if data[column].isnull().any():
    impute = SimpleImputer(missing_values=np.nan, strategy='mean')
    impute.fit(data[[column]])
    data[column] = impute.transform(data[[column]])

"""#Checking the count of null values after imputing"""

data.isnull().sum()

"""##Feature Scaling

### Spliting The Dataset For Training and Testing
"""

from sklearn.model_selection import train_test_split
features = data.columns[0:-1]
target =  data.columns[-1]

X = data[features]
y = data[target]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
print(X_train.shape)
print(X_test.shape)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("per-feature minimum before scaling:\n {}".format(X_train.min(axis=0)))
print("per-feature maximum before scaling:\n {}".format(X_train.max(axis=0)))

print("per-feature minimum after scaling:\n {}".format(
    X_train_scaled.min(axis=0)))
print("per-feature maximum after scaling:\n {}".format(
    X_train_scaled.max(axis=0)))

"""## Effect of using MinMax Scaler:

### Accuracy without scaling
"""

knn=KNeighborsClassifier()
knn.fit(X_train, y_train)

print("Test set accuracy: {:.2f}".format(knn.score(X_test, y_test)))

decision=DecisionTreeClassifier()
decision.fit(X_train, y_train)

print("Test set accuracy: {:.2f}".format(decision.score(X_test, y_test)))

lr = LogisticRegression()
lr.fit(X_train, y_train)

print("Test set accuracy: {:.2f}".format(lr.score(X_test, y_test)))

naive_bayes = GaussianNB()
naive_bayes.fit(X_train, y_train)
print("Test set accuracy: {:.2f}".format(naive_bayes.score(X_test, y_test)))

"""### We can see that accuracy significantly improves if we train on scaled data."""

knn.fit(X_train_scaled, y_train)

# scoring on the scaled test set
print("Scaled test set accuracy: {:.2f}".format(
    knn.score(X_test_scaled, y_test)))

decision.fit(X_train_scaled, y_train)

# scoring on the scaled test set
print("Scaled test set accuracy: {:.2f}".format(
    decision.score(X_test_scaled, y_test)))

lr.fit(X_train_scaled, y_train)
print("Test set accuracy: {:.2f}".format(lr.score(X_test_scaled, y_test)))

naive_bayes.fit(X_train_scaled, y_train)
print("Test set accuracy: {:.2f}".format(lr.score(X_test_scaled, y_test)))

"""##Checking if there are any catagorical values in our dataset"""

data.info()
#there are no catagorical values in our dataset

"""##Feature Selection"""

data_corr = data.corr()
data_corr

sns.heatmap(data_corr, cmap = 'YlGnBu')

"""##Finding out the column where the correlation value is greater than 0.75 more than 10 times"""

lst=[]
for column in data_corr.columns:
    cnt=0
    for other_column in data_corr.columns:
        if column != other_column and data_corr[column][other_column]>=0.75:
          cnt+=1
    if cnt>10:
      lst.append(column)
print(lst)

"""## Dropping the irrelvant or the more correlated features"""

# Create a list of redundant column names to drop
to_drop = ['qty_questionmark_directory', 'qty_equal_directory', 'qty_at_directory', 'qty_and_directory', 'qty_exclamation_directory', 'qty_space_directory', 'qty_tilde_directory', 'qty_comma_directory', 'qty_plus_directory', 'qty_asterisk_directory', 'qty_hashtag_directory', 'qty_dollar_directory', 'qty_dot_file', 'qty_underline_file', 'qty_slash_file', 'qty_questionmark_file', 'qty_equal_file', 'qty_at_file', 'qty_and_file', 'qty_exclamation_file', 'qty_space_file', 'qty_tilde_file', 'qty_comma_file', 'qty_plus_file', 'qty_asterisk_file', 'qty_hashtag_file', 'qty_dollar_file', 'qty_questionmark_params', 'qty_equal_params', 'qty_at_params', 'qty_exclamation_params', 'qty_space_params', 'qty_tilde_params', 'qty_comma_params', 'qty_plus_params', 'qty_asterisk_params', 'qty_hashtag_params', 'qty_dollar_params', 'tld_present_params', 'qty_params']



# Drop those columns from the dataset
cleaned_data = data.drop(to_drop, axis=1)

# Print out the head of the new dataset
cleaned_data

"""##Heatmap after cleaning the dataset"""

data_corr = cleaned_data.corr()
data_corr
sns.heatmap(data_corr, cmap = 'YlGnBu')

"""##Splitting the Cleaned dataset"""

# Finalize features and target from cleaned_data
features = cleaned_data.columns[0:-1]
target = cleaned_data.columns[-1]

X = cleaned_data[features]
y = cleaned_data[target]

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale the data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""##KNN train predict and evaluate"""

# Initialize and train
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred_knn = knn.predict(X_test_scaled)
print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))

"""##Decision Tree train predict and evaluate"""

decision = DecisionTreeClassifier(max_depth=5, random_state=42)
decision.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred_dt = decision.predict(X_test_scaled)
print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

"""##Logistic Regression train predict and evaluate"""

lr = LogisticRegression(random_state=42)
lr.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred_lr = lr.predict(X_test_scaled)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

"""##Naive Bayes train predict and evaluate"""

naive_bayes = GaussianNB()
naive_bayes.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred_nb = naive_bayes.predict(X_test_scaled)
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print(classification_report(y_test, y_pred_nb))

"""##Bar chart comparison of all models"""

accuracy_knn = knn.score(X_test_scaled, y_test)
accuracy_decision = decision.score(X_test_scaled, y_test)
accuracy_lr = lr.score(X_test_scaled, y_test)
models = ['KNN', 'Decision Tree', 'Logistic Regression', 'Naive Bayes']
accuracies = [0.927645788336933, 0.8994543594407184, 0.8916107764010458, 0.8410253495509833]

plt.figure(figsize=(7, 6))
bars = plt.bar(models, accuracies, color=['blue', 'green', 'red', 'yellow'])

plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Comparison of Model Accuracies')
plt.ylim(0, 1)  # Assuming accuracy values are between 0 and 1

# Show the plot
plt.show()

"""##Confusion Metrices for each model"""

print("Confusion Matrix for KNN:")
print(confusion_matrix(y_test, y_pred_knn))

cm = confusion_matrix(y_test, y_pred_knn)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix for KNN")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print("Confusion Matrix for Decision Tree:")
print(confusion_matrix(y_test, y_pred_dt))

cm=confusion_matrix(y_test, y_pred_dt)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix for Decision Tree")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print("Confusion Matrix for Logistic Regression:")
print(confusion_matrix(y_test, y_pred_lr))


cm = confusion_matrix(y_test, y_pred_lr)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix for Logistic Regression")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print("Confusion Matrix for Naive Bayes:")
print(confusion_matrix(y_test, y_pred_nb))


cm = confusion_matrix(y_test, y_pred_nb)


plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix for Naive Bayes")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()